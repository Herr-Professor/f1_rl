model = "Qwen/Qwen3-30B-A3B-Thinking-2507"
max_steps = 200
batch_size = 128
rollouts_per_example = 8
trajectory_strategy = "interleaved"

[sampling]
max_tokens = 900

[[env]]
id = "herr-professor/f1-strategy"
args = { deep_reasoning = true, use_tools = true, multi_turn = false, multi_env = true }

[eval]
interval = 100
num_examples = 20
rollouts_per_example = 1
# NOTE: Setting this to false currently trips a prime-rl/orchestrator CLI flag
# translation bug ("--eval.no-eval-base-model"). Keep true (or remove the field)
# to ensure hosted runs start reliably.
eval_base_model = true

[[eval.env]]
id = "herr-professor/f1-strategy"
args = { deep_reasoning = true, use_tools = true, multi_turn = false, multi_env = true }
